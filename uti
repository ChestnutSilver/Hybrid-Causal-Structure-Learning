import numpy as np
from sklearn.preprocessing import OneHotEncoder
from astropy import stats


def normalize_biweight(x, eps=1e-10):#作用应该是返回x的归一化双权值，如果分布的标准差太小则用标准化的标准差代替
    median = np.median(x)#计算分布的中位数
    scale = stats.biweight.biweight_scale(x)#返回分布的双权重比例。双权标度是确定分布标准差的稳健统计
    if np.std(x) < 1e+2 or np.isnan(scale) or scale < 1e-4:#np.std()是得到x标准差,np.isnan()判断是否非数字
        norm =  (x-np.mean(x))/np.std(x)#太小或者非数字时就用个体标准差/样本标准差代替双权值
    else:
        norm = (x - median) / (scale + eps)#否则返回（x-中位数）/（双权标准差+eps）,eps不清楚是什么
    return norm


def normalize(x):
    norm = lambda x: (x-np.mean(x))/np.std(x)#标准化标准差
    return np.apply_along_axis(norm, 0, x)#用lambda表达式代替函数，将x中的数据标准差标准化


def data_preprocess(df):#把数据编码成独热码并返回

    def _encoding(i):
        if df.iloc[:,i].dtype == 'O' or df.iloc[:, i].dtype.name == 'category':#每行第i个输入数据是分类有关的
            tempX = df.iloc[:, i].values.reshape(-1, 1)#把数据变成只有1列的，行自动计算
            enc = OneHotEncoder(handle_unknown='ignore')#创建一个对象，把每一行数据编成独热码，参数表示遇到没标识过的时不报错
            enc.fit(tempX)#加入训练数据（也就是告诉这个对象有哪些类别）
            out = enc.transform(tempX).toarray()#得到tempX的独热码
        else:
            out = df.iloc[:, i].values.reshape(-1, 1)#不是则直接变成1列，不编码
        return out
    p = df.shape[1]#得到df的列数
    X_encode = [_encoding(i) for i in np.arange(p)]#每一列编码一次
    return X_encode#返回编码


def evaluate_binary(trueG, estG):#trueG应该是真实值，estG是估计值，作用应该是计算准确率召回率等，与下面的函数不同的是这应该是一种二分评估？
    #TP：被模型预测为正类的正样本
    #TN：被模型预测为负类的负样本
    #FP：被模型预测为正类的负样本
    #FN：被模型预测为负类的正样本
    #FD应该是预测错误的相反正样本，即01预测为10，10预测为01
    #MD什么含义不清楚，但知道01，10都预测为11
    #FPMD什么含义不清楚，但知道是00预测为11
    #TP与TN是预测正确的
    TP, TN, FP, FN, FD, MD, FPMD = 0, 0, 0, 0, 0, 0, 0
    n_node = trueG.shape[0]#行数
    for i in range(1, n_node):
        for j in range(i):
            #貌似 trueG中10 01代表正样本，00代表负样本
            if trueG[i, j] == 1 and trueG[j, i] == 0 and estG[i, j] == 1 and \
                    estG[j, i] == 0:
                TP += 1
            if trueG[i, j] == 0 and trueG[j, i] == 1 and estG[i, j] == 0 and \
                    estG[j, i] == 1:
                TP += 1
            if trueG[i, j] == 0 and trueG[j, i] == 0 and estG[i, j] == 0 and \
                    estG[j, i] == 0:
                TN += 1
            if trueG[i, j] == 0 and trueG[j, i] == 0 and estG[i, j] == 1 and \
                    estG[j, i] == 0:
                FP += 1
            if trueG[i, j] == 0 and trueG[j, i] == 0 and estG[i, j] == 0 and \
                    estG[j, i] == 1:
                FP += 1
            if trueG[i, j] == 1 and trueG[j, i] == 0 and estG[i, j] == 0 and \
                    estG[j, i] == 0:
                FN += 1
            if trueG[i, j] == 0 and trueG[j, i] == 1 and estG[i, j] == 0 and \
                    estG[j, i] == 0:
                FN += 1
            if trueG[i, j] == 1 and trueG[j, i] == 0 and estG[i, j] == 0 and \
                    estG[j, i] == 1:
                FD += 1
            if trueG[i, j] == 0 and trueG[j, i] == 1 and estG[i, j] == 1 and \
                    estG[j, i] == 0:
                FD += 1
            if trueG[i, j] == 0 and trueG[j, i] == 1 and estG[i, j] == 1 and \
                    estG[j, i] == 1:
                MD += 1
            if trueG[i, j] == 1 and trueG[j, i] == 0 and estG[i, j] == 1 and \
                    estG[j, i] == 1:
                MD += 1
            if trueG[i, j] == 0 and trueG[j, i] == 0 and estG[i, j] == 1 and \
                    estG[j, i] == 1:
                FPMD += 1
    if (TP + FP + FD)>0:
        Precision = TP / (TP + FP + FD)#计算精确率
    else:
        Precision = 0.0
    Recall = TP / sum(sum(trueG))#计算总召回率

    if (TP + FN + FD) > 0:
        Recall1 = TP / (TP + FN + FD)#计算正样本召回率
    else:
        Recall1 = 0.0
    SHD = sum(sum((trueG != estG) | np.transpose((trueG != estG)))) / 2#transpose（）是转置，也就是计算所有trueG[i,j][j,i]!=estG[i,j][j,i]的和
    return {'TP': TP, 'TN': TN, 'FP': FP, 'FN': FN, 'FD': FD, 'MD': MD,
            'FPMD': FPMD,'Precision': Precision, 'Recall': Recall,
            'Recall_NOMD': Recall1, 'SHD': SHD}


def skeleton_metrics(trueG, estG):#计算被预测正确或错误的正负样本。与上面不同的是这里只要[i,j]或[j,i]满足一个就可以
    #TP：被模型预测为正类的正样本
    #TN：被模型预测为负类的负样本
    #FP：被模型预测为正类的负样本
    #FN：被模型预测为负类的正样本
    TP,TN,FP,FN = 0,0,0,0
    n = trueG.shape[0]
    for i in range(n):
        for j in range(i):
            if trueG[i, j] == 1 or trueG[j, i] == 1:
                if estG[i, j] != 0 or estG[j, i] != 0:
                    TP += 1
                else:
                    FN += 1
            else:
                if estG[i, j] == 0 and estG[j, i] == 0:
                    TN += 1
                else:
                    FP += 1
    return {'TP': TP, 'TN': TN, 'FP': FP, 'FN': FN}


def check_connect_skel(skeleton, i, j):#在i的范围内检查j是否已经存在，skeleton应该是一个邻接矩阵
    depth = set.union(set(np.where(skeleton[:,i]==1)[0]),#将第i行或第i列中为1的行索引索引加入集合
                      set(np.where(skeleton[i,:]==1)[0]))
    checked = depth
    while depth:
        if j in depth:
            return True
        next = {}
        for k in depth:
            next = set.union(next, set.union(set(np.where(skeleton[:,k]==1)[0]),
                                             set(np.where(skeleton[k,:]==1)[0])))
        depth = set.difference(next, checked)#获得有差异的集合，即还没被检查过的
        checked = set.union(checked, depth)#更新已经检查过的
    return False


def reachable(dag, fr, to):#这里感觉有点问题，因为np.where(dag[fr,:]==1)[0]返回的是第fr行中所有=1的元素的行索引，也就是行索引还是fr
    depth = set(np.where(dag[fr,:]==1)[0])
    checked = depth
    while depth:
        if to in depth:
            return True
        next = set()
        for k in depth:
            next = set.union(next, set(np.where(dag[k,:]==1)[0]))
        depth = set.difference(next, checked)
        checked = set.union(checked, depth)
    return False
